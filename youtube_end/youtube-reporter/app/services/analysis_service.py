from typing import Dict, Any, List
from datetime import datetime
import uuid
from fastapi import HTTPException
from langchain.text_splitter import RecursiveCharacterTextSplitter
from app.models.analysis import AnalysisResponse
from app.services.langgraph_service import langgraph_service
from app.services.rouge_service import rouge_service
from app.services.youtube_processing_service import youtube_processing_service

class AnalysisService:
    def __init__(self):
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200
        )

    async def analyze_youtube_with_fsm(self, youtube_url: str, job_id: str = None, user_id: str = None, user_email: str = None) -> AnalysisResponse:
        """LangGraph FSMÏùÑ ÏÇ¨Ïö©Ìïú YouTube Î∂ÑÏÑù - YouTubeProcessingService ÌÜµÌï©"""
        try:
            print(f"=== YouTube Î∂ÑÏÑù ÏãúÏûë ===")
            print(f"YouTube URL: {youtube_url}")
            print(f"Job ID: {job_id}")
            print(f"User ID: {user_id}")
            print(f"User Email: {user_email}")
            
            # 1. YouTubeProcessingServiceÎ°ú YouTube Ï≤òÎ¶¨ (vidcap API ‚Üí S3 Ï†ÄÏû•)
            youtube_result = await youtube_processing_service.process_youtube_to_s3(
                youtube_url=youtube_url,
                user_email=user_email or "anonymous@example.com"
            )
            
            print(f"‚úÖ YouTube Ï≤òÎ¶¨ ÏôÑÎ£å: {youtube_result['s3_key']}")
            
            # 2. LangGraph FSM Î∂ÑÏÑù Ïã§Ìñâ (S3Ïóê Ï†ÄÏû•Îêú transcripts ÌååÏùº ÏÇ¨Ïö©)
            fsm_result = await langgraph_service.analyze_youtube_with_fsm(
                youtube_url=youtube_url,
                job_id=job_id,
                user_id=user_id
            )
            
            # 3. ROUGE ÌèâÍ∞Ä Í≥ÑÏÇ∞
            rouge_scores = None
            if fsm_result and fsm_result.get('final_output'):
                try:
                    # ÏõêÎ≥∏ ÌÖçÏä§Ìä∏ (caption)ÏôÄ ÏöîÏïΩ ÌÖçÏä§Ìä∏ Ï∂îÏ∂ú
                    original_text = fsm_result.get('caption', '')
                    summary_text = ''
                    
                    # final_outputÏóêÏÑú ÏöîÏïΩ ÌÖçÏä§Ìä∏ Ï∂îÏ∂ú
                    final_output = fsm_result['final_output']
                    if isinstance(final_output, dict) and 'sections' in final_output:
                        summary_text = ' '.join([section.get('content', '') for section in final_output['sections']])
                    elif isinstance(final_output, str):
                        summary_text = final_output
                    
                    # ROUGE Ï†êÏàò Í≥ÑÏÇ∞ (ÏõêÎ≥∏Í≥º ÏöîÏïΩÏù¥ Î™®Îëê ÏûàÏùÑ ÎïåÎßå)
                    if original_text and summary_text:
                        rouge_scores = rouge_service.calculate_rouge_scores(original_text, summary_text)
                        print(f"\nüéØ YouTube URL: {youtube_url}")
                        
                except Exception as rouge_error:
                    print(f"‚ö†Ô∏è ROUGE Í≥ÑÏÇ∞ Ï§ë Ïò§Î•ò: {rouge_error}")
            
            analysis_results = {
                "fsm_analysis": fsm_result,
                "rouge_scores": rouge_scores,
                "method": "langgraph_fsm",
                "youtube_processing": youtube_result,  # YouTube Ï≤òÎ¶¨ Í≤∞Í≥º Ï∂îÍ∞Ä
                "s3_storage": {
                    "transcripts_file": youtube_result["s3_key"],
                    "report_file": f"reports/{user_id or 'anonymous'}/{job_id or 'unknown'}_report.json",
                    "metadata_file": f"metadata/{user_id or 'anonymous'}/{job_id or 'unknown'}_metadata.json"
                }
            }
            
            return AnalysisResponse(
                id=job_id or str(uuid.uuid4()),
                status="completed",
                analysis_results=analysis_results,
                created_at=datetime.now(),
                completed_at=datetime.now()
            )
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"YouTube FSM Î∂ÑÏÑù Ïã§Ìå®: {str(e)}")

    async def analyze_document(self, content: str, metadata: Dict[str, Any]) -> AnalysisResponse:
        """Î¨∏ÏÑú Î∂ÑÏÑù"""
        try:
            # Î¨∏ÏÑú Î∂ÑÌï†
            docs = self.text_splitter.split_text(content)
            
            # Î¨∏ÏÑú Î∂ÑÏÑù
            analysis_results = await self._analyze_document_content(docs, metadata)
            
            # ROUGE ÌèâÍ∞Ä (Î¨∏ÏÑú ÏöîÏïΩÏù¥ ÏûàÎäî Í≤ΩÏö∞)
            rouge_scores = None
            if analysis_results.get('analysis') and content:
                try:
                    rouge_scores = rouge_service.calculate_rouge_scores(content, analysis_results['analysis'])
                    print(f"\nüìÑ Î¨∏ÏÑú Î∂ÑÏÑù ROUGE ÌèâÍ∞Ä ÏôÑÎ£å")
                except Exception as rouge_error:
                    print(f"‚ö†Ô∏è Î¨∏ÏÑú ROUGE Í≥ÑÏÇ∞ Ï§ë Ïò§Î•ò: {rouge_error}")
            
            analysis_results['rouge_scores'] = rouge_scores
            
            return AnalysisResponse(
                id=str(uuid.uuid4()),
                status="completed",
                analysis_results=analysis_results,
                created_at=datetime.now(),
                completed_at=datetime.now()
            )
            
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"Î¨∏ÏÑú Î∂ÑÏÑù Ïã§Ìå®: {str(e)}")





    async def _analyze_document_content(self, docs: List[str], metadata: Dict[str, Any]) -> Dict[str, Any]:
        """Î¨∏ÏÑú ÎÇ¥Ïö© Î∂ÑÏÑù - LangGraph ServiceÏùò Claude ÏÇ¨Ïö©"""
        from app.services.langgraph_service import llm
        from langchain.prompts import ChatPromptTemplate
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", "You are an expert document analyzer. Analyze the following document content and provide a comprehensive summary and insights."),
            ("user", "Document Content: {content}\nMetadata: {metadata}\n\nPlease provide a detailed analysis and summary.")
        ])
        
        messages = prompt.format_messages(content=docs, metadata=metadata)
        result = llm.invoke(messages)
        
        return {"analysis": result.content}



analysis_service = AnalysisService()